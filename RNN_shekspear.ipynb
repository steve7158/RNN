{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "RNN_shekspear.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJr3QivOX31g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5ow97LX8n5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9cd0c374-6694-411b-f576-a8900322798f"
      },
      "source": [
        "!git clone https://github.com/steve7158/RNN.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'RNN'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mbBrfEOX31x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file='RNN/wonderland.txt'\n",
        "raw_text=open(file, 'r', encoding='utf-8').read()\n",
        "raw_text=raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVL-OzwlX315",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars=sorted(list(set(raw_text)))\n",
        "chars_to_int=dict((c,i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYaINjk0X31_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2fdb109a-bb32-4c41-e610-9ad993574bde"
      },
      "source": [
        "n_chars=len(raw_text)\n",
        "n_vocab=len(chars)\n",
        "print('total charecters: ',n_chars)\n",
        "print('total vocab: ', n_vocab)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total charecters:  163781\n",
            "total vocab:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ1c5AKOX32G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d52676d-99c6-4756-fb80-419cfdace371"
      },
      "source": [
        "seq_length=100\n",
        "dataX=[]\n",
        "dataY=[]\n",
        "for i in range(0, n_chars-seq_length, 1):\n",
        "    seq_in=raw_text[i:i+seq_length]\n",
        "    seq_out=raw_text[i+seq_length]\n",
        "    dataX.append([chars_to_int[char] for char in seq_in])\n",
        "    dataY.append(chars_to_int[seq_out])\n",
        "n_patterns=len(dataX)\n",
        "print('Total pattern:  ', n_patterns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total pattern:   163681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo8bwYDpX32M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26b4a853-9525-497f-a0fc-3c7d2eb9e7ac"
      },
      "source": [
        "X=np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X=X/float(n_vocab)\n",
        "y=np_utils.to_categorical(dataY)\n",
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163681, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znwuz7iqX32R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "aeeb57cc-7938-4e20-a100-f4ac2fede773"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_83glbfbAoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bc38fac-a47b-415e-ccac-4edfd659ca2d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsKd5RPX32V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZdP6dNFX32a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46bfd845-0548-4f8d-d7da-144802c7641c"
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-01-2.9906.hdf5')\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163681/163681 [==============================] - 311s 2ms/step - loss: 2.8180\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.81799, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-01-2.8180.hdf5\n",
            "Epoch 2/20\n",
            "163681/163681 [==============================] - 311s 2ms/step - loss: 2.7222\n",
            "\n",
            "Epoch 00002: loss improved from 2.81799 to 2.72221, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-02-2.7222.hdf5\n",
            "Epoch 3/20\n",
            "163681/163681 [==============================] - 302s 2ms/step - loss: 2.6489\n",
            "\n",
            "Epoch 00003: loss improved from 2.72221 to 2.64887, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-03-2.6489.hdf5\n",
            "Epoch 4/20\n",
            "163681/163681 [==============================] - 305s 2ms/step - loss: 2.5899\n",
            "\n",
            "Epoch 00004: loss improved from 2.64887 to 2.58994, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-04-2.5899.hdf5\n",
            "Epoch 5/20\n",
            "163681/163681 [==============================] - 309s 2ms/step - loss: 2.5351\n",
            "\n",
            "Epoch 00005: loss improved from 2.58994 to 2.53512, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-05-2.5351.hdf5\n",
            "Epoch 6/20\n",
            "163681/163681 [==============================] - 303s 2ms/step - loss: 2.4827\n",
            "\n",
            "Epoch 00006: loss improved from 2.53512 to 2.48269, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-06-2.4827.hdf5\n",
            "Epoch 7/20\n",
            "163681/163681 [==============================] - 303s 2ms/step - loss: 2.4358\n",
            "\n",
            "Epoch 00007: loss improved from 2.48269 to 2.43582, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-07-2.4358.hdf5\n",
            "Epoch 8/20\n",
            "163681/163681 [==============================] - 319s 2ms/step - loss: 2.3947\n",
            "\n",
            "Epoch 00008: loss improved from 2.43582 to 2.39472, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-08-2.3947.hdf5\n",
            "Epoch 9/20\n",
            "163681/163681 [==============================] - 315s 2ms/step - loss: 2.3571\n",
            "\n",
            "Epoch 00009: loss improved from 2.39472 to 2.35712, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-09-2.3571.hdf5\n",
            "Epoch 10/20\n",
            "163681/163681 [==============================] - 303s 2ms/step - loss: 2.3209\n",
            "\n",
            "Epoch 00010: loss improved from 2.35712 to 2.32092, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-10-2.3209.hdf5\n",
            "Epoch 11/20\n",
            "163681/163681 [==============================] - 306s 2ms/step - loss: 2.2862\n",
            "\n",
            "Epoch 00011: loss improved from 2.32092 to 2.28620, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-11-2.2862.hdf5\n",
            "Epoch 12/20\n",
            "163681/163681 [==============================] - 304s 2ms/step - loss: 2.2556\n",
            "\n",
            "Epoch 00012: loss improved from 2.28620 to 2.25561, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-12-2.2556.hdf5\n",
            "Epoch 13/20\n",
            "163681/163681 [==============================] - 296s 2ms/step - loss: 2.2262\n",
            "\n",
            "Epoch 00013: loss improved from 2.25561 to 2.22619, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-13-2.2262.hdf5\n",
            "Epoch 14/20\n",
            "163681/163681 [==============================] - 297s 2ms/step - loss: 2.1961\n",
            "\n",
            "Epoch 00014: loss improved from 2.22619 to 2.19613, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-14-2.1961.hdf5\n",
            "Epoch 15/20\n",
            "163681/163681 [==============================] - 322s 2ms/step - loss: 2.1686\n",
            "\n",
            "Epoch 00015: loss improved from 2.19613 to 2.16865, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-15-2.1686.hdf5\n",
            "Epoch 16/20\n",
            "163681/163681 [==============================] - 308s 2ms/step - loss: 2.1402\n",
            "\n",
            "Epoch 00016: loss improved from 2.16865 to 2.14019, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-16-2.1402.hdf5\n",
            "Epoch 17/20\n",
            "163681/163681 [==============================] - 307s 2ms/step - loss: 2.1178\n",
            "\n",
            "Epoch 00017: loss improved from 2.14019 to 2.11777, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-17-2.1178.hdf5\n",
            "Epoch 18/20\n",
            "163681/163681 [==============================] - 306s 2ms/step - loss: 2.0940\n",
            "\n",
            "Epoch 00018: loss improved from 2.11777 to 2.09395, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-18-2.0940.hdf5\n",
            "Epoch 19/20\n",
            "163681/163681 [==============================] - 308s 2ms/step - loss: 2.0725\n",
            "\n",
            "Epoch 00019: loss improved from 2.09395 to 2.07253, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-19-2.0725.hdf5\n",
            "Epoch 20/20\n",
            "163681/163681 [==============================] - 306s 2ms/step - loss: 2.0491\n",
            "\n",
            "Epoch 00020: loss improved from 2.07253 to 2.04912, saving model to /content/gdrive/My Drive/My_AI_proj/RNN_shakespear/weights-improvement-20-2.0491.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01f0bd3b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arD-VKG3X32k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPAbBvKI-rQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "487bcb49-0559-42cc-e7c5-922637ba41ae"
      },
      "source": [
        "...\n",
        "import sys\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[21]\n",
        "print (\"Seed:\")\n",
        "print( \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "print('GENERATING CHARECTERS', len(pattern))\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print( \"\\nDone.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" alice's adventures in wonderland, by lewis carroll\n",
            "\n",
            "this ebook is for the use of anyone anywhere at  \"\n",
            "GENERATING CHARECTERS 100\n",
            "toe project gutenberg-tm electronic works in aly cayer oo tee porject gutenberg-lm electronic works in aly caner aededs to the pooject gutenberg-lm electronic works in aly caner aerer and lot cerer an ooe cerer oo the pooject gutenberg-lm electronic works in aly caner aoo toe pooject gutenberg-tm electronic works in aly caner aededs to the pooject gutenberg-lm electronic works in aly caner aerer and lot cerer an ooe cerer oo the pooject gutenberg-lm electronic works in aly caner aoo toe pooject gutenberg-tm electronic works in aly caner aededs to the pooject gutenberg-lm electronic works in aly caner aerer and lot cerer an ooe cerer oo the pooject gutenberg-lm electronic works in aly caner aoo toe pooject gutenberg-tm electronic works in aly caner aededs to the pooject gutenberg-lm electronic works in aly caner aerer and lot cerer an ooe cerer oo the pooject gutenberg-lm electronic works in aly caner aoo toe pooject gutenberg-tm electronic works in aly caner aededs to the pooject guten\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8_0YBgp-1Y5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9983ceb8-6d73-4ecb-db5e-874b901b3864"
      },
      "source": [
        "print(dataX[21])\n",
        "\n",
        "print(int_to_char[1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[32, 43, 40, 34, 36, 7, 50, 1, 32, 35, 53, 36, 45, 51, 52, 49, 36, 50, 1, 40, 45, 1, 54, 46, 45, 35, 36, 49, 43, 32, 45, 35, 11, 1, 33, 56, 1, 43, 36, 54, 40, 50, 1, 34, 32, 49, 49, 46, 43, 43, 0, 0, 51, 39, 40, 50, 1, 36, 33, 46, 46, 42, 1, 40, 50, 1, 37, 46, 49, 1, 51, 39, 36, 1, 52, 50, 36, 1, 46, 37, 1, 32, 45, 56, 46, 45, 36, 1, 32, 45, 56, 54, 39, 36, 49, 36, 1, 32, 51, 1]\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut82So_lB43z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6876dcfc-befc-486e-a83a-bcffe40522a4"
      },
      "source": [
        "print(int_to_char[32], int_to_char[43], int_to_char[40], int_to_char[34], int_to_char[36], int_to_char[7], int_to_char[50])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a l i c e ' s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQYoRU9rF_-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}